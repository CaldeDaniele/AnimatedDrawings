# Copyright (c) Meta Platforms, Inc. and affiliates.
# This source code is licensed under the MIT license found in the
# LICENSE file in the root directory of this source tree.

inference_address=http://0.0.0.0:8080
management_address=http://0.0.0.0:8081
metrics_address=http://0.0.0.0:8082
model_store=/home/torchserve/model-store
load_models=all

# --- Performance tuning (Animated Drawings case-study: workers=1, GPU) ---
# Use 1 worker per model to avoid contention (best for detector + pose estimator).
default_workers_per_model=1
# Use 1 GPU for both models (round-robin); set to 2 if you have 2 GPUs.
number_of_gpu=1
# Lower latency: batch 1, short delay. For higher throughput use batch_size=4 and maxBatchDelay=100.
models={\
  "drawn_humanoid_detector": {\
    "1.0": {\
      "minWorkers": 1,\
      "maxWorkers": 1,\
      "batchSize": 1,\
      "maxBatchDelay": 50\
    }\
  },\
  "drawn_humanoid_pose_estimator": {\
    "1.0": {\
      "minWorkers": 1,\
      "maxWorkers": 1,\
      "batchSize": 1,\
      "maxBatchDelay": 50\
    }\
  }\
}
# Frontend threads for handling concurrent connections (default: JVM logical cores).
number_of_netty_threads=4
